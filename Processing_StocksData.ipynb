{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  stock_symbol  order_volume\n",
      "0       OIH           5000.0\n",
      "1       SPY           2000.0\n",
      "2       DRYS          1209.0\n",
      "3       ZVZZT          577.0\n",
      "4       AAPL           495.0\n",
      "5       PTR            400.0\n",
      "6       UYG            400.0\n",
      "7       FXP            320.0\n",
      "8       DIA            229.0\n",
      "9       BAC            210.0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import functools\n",
    "import numpy as np\n",
    "\n",
    "class PitchData():\n",
    "    def __init__(self,raw_df):\n",
    "        self.df = raw_df\n",
    "    \n",
    "    #Extract message_length and message_type\n",
    "    def extract_raw_data(self):\n",
    "        self.df['message_length']= self.df['raw_message_data'].str.len()\n",
    "        self.df['message_type'] = self.df['raw_message_data'].str.slice(9,10,1).astype(str)\n",
    "    \n",
    "    #Create seperate dataframes for each message types\n",
    "    def createMultipleDataFrames(self):\n",
    "        active_df = self.df[self.df.message_type == 'A'].reset_index(drop=True)\n",
    "        cancel_df = self.df[self.df.message_type == 'X'].reset_index(drop=True)\n",
    "        executed_df = self.df[self.df.message_type == 'E'].reset_index(drop=True)\n",
    "        trade_df = self.df[self.df.message_type == 'P'].reset_index(drop=True)\n",
    "        \n",
    "        return active_df,cancel_df,executed_df,trade_df\n",
    "\n",
    "\n",
    "class AggregateData():\n",
    "    def __init__(self,active_df,cancel_df,executed_df,trade_df):\n",
    "        self.active_df = active_df\n",
    "        self.cancel_df = cancel_df\n",
    "        self.executed_df = executed_df\n",
    "        self.trade_df = trade_df\n",
    "        self.active_agg = None\n",
    "        self.cancel_agg = None\n",
    "        self.executed_agg= None\n",
    "        self.trade_agg = None\n",
    "        self.orders_agg = None\n",
    "        self.volume_agg = None\n",
    "    \n",
    "    # Parse and process AddOrder, active messages based on the CBOE book format\n",
    "    def processActiveOrders(self):\n",
    "        active_df = self.active_df\n",
    "        #Ignore the first character 'S'\n",
    "        active_df['raw_message_data'] = active_df['raw_message_data'].str[1:]\n",
    "        active_df['time_stamp'] = active_df['raw_message_data'].str.slice(0,8,1)#slice parameters can be given from message schemas dictionary as well\n",
    "        active_df['order_ID'] = active_df['raw_message_data'].str.slice(9,21,1)\n",
    "        active_df['side_indicator'] = active_df['raw_message_data'].str.slice(21,22,1)\n",
    "        active_df['shares'] = active_df['raw_message_data'].str.slice(22,28,1)\n",
    "        active_df['share_symbol'] = active_df['raw_message_data'].str.slice(28,34,1)\n",
    "        active_df['price'] = active_df['raw_message_data'].str.slice(34,44,1)\n",
    "        active_df['display'] = active_df['raw_message_data'].str.slice(44,45,1)\n",
    "        active_df['shares'] = active_df['shares'].astype(int)\n",
    "        return active_df\n",
    "    \n",
    "    # Parse and process Cancel Order messages based on the CBOE book format\n",
    "    def processCancelOrders(self):\n",
    "        cancel_df = self.cancel_df\n",
    "        #Ignore the first character 'S'\n",
    "        cancel_df['raw_message_data'] = cancel_df['raw_message_data'].str[1:]\n",
    "        cancel_df['time_stamp'] = cancel_df['raw_message_data'].str.slice(0,8,1)\n",
    "        cancel_df['order_ID'] = cancel_df['raw_message_data'].str.slice(9,21,1)\n",
    "        cancel_df['cancelled_shares'] = cancel_df['raw_message_data'].str.slice(21,27,1)\n",
    "        cancel_df['cancelled_shares'] = cancel_df['cancelled_shares'].astype(int)\n",
    "        return cancel_df\n",
    "        \n",
    "    # Parse and process Execute Order messages based on the CBOE book format\n",
    "    def processExecutedOrders(self):\n",
    "        executed_df = self.executed_df\n",
    "        #Ignore the first character 'S'\n",
    "        executed_df['raw_message_data'] = executed_df['raw_message_data'].str[1:]\n",
    "        executed_df['time_stamp'] = executed_df['raw_message_data'].str.slice(0,8,1)\n",
    "        executed_df['order_ID'] = executed_df['raw_message_data'].str.slice(9,21,1)\n",
    "        executed_df['executed_shares'] = executed_df['raw_message_data'].str.slice(21,27,1)\n",
    "        executed_df['execution_ID'] = executed_df['raw_message_data'].str.slice(27,39,1)\n",
    "        executed_df['executed_shares'] = executed_df['executed_shares'].astype(int)\n",
    "        return executed_df\n",
    "    \n",
    "    # Parse and process Trade messages based on the CBOE book format\n",
    "    def processTradeOrders(self):\n",
    "        trade_df = self.trade_df\n",
    "        #Ignore the first character 'S'\n",
    "        trade_df['raw_message_data'] = trade_df['raw_message_data'].str[1:]\n",
    "        trade_df['time_stamp'] = trade_df['raw_message_data'].str.slice(0,8,1)\n",
    "        trade_df['order_ID'] = trade_df['raw_message_data'].str.slice(9,21,1)\n",
    "        trade_df['side_indicator'] = trade_df['raw_message_data'].str.slice(21,22,1)\n",
    "        trade_df['shares'] = trade_df['raw_message_data'].str.slice(22,28,1)\n",
    "        trade_df['share_symbol'] = trade_df['raw_message_data'].str.slice(28,34,1)\n",
    "        trade_df['price'] = trade_df['raw_message_data'].str.slice(34,44,1)\n",
    "        trade_df['execution_id'] = trade_df['raw_message_data'].str.slice(44,56,1)\n",
    "        trade_df['shares'] = trade_df['shares'].astype(int)\n",
    "        return trade_df\n",
    "    \n",
    "    # Parent function to parse and create different dataframes for each message type\n",
    "    def process_orders(self):\n",
    "        self.active_df = self.processActiveOrders()\n",
    "        self.cancel_df = self.processCancelOrders()\n",
    "        self.executed_df = self.processExecutedOrders()\n",
    "        self.trade_df = self.processTradeOrders()\n",
    "    \n",
    "    # Gets the sums of all the shares for a share_symbol which is grouped by order-ID\n",
    "    def process_order_aggregates(self):\n",
    "        self.active_agg = self.active_df.groupby(by =['order_ID','share_symbol']).agg({'shares':'sum'}).reset_index()\n",
    "        self.cancel_agg = self.cancel_df.groupby(by =['order_ID']).agg({'cancelled_shares':'sum'}).reset_index()\n",
    "        self.executed_agg = self.executed_df.groupby(by =['order_ID']).agg({'executed_shares':'sum'}).reset_index()\n",
    "        self.trade_agg = self.trade_df.groupby(by =['order_ID','share_symbol']).agg({'shares':'sum'}).reset_index()\n",
    "    \n",
    "    # Gets the sums of all the shares for a share_symbol which is grouped by order-ID. Also generates column called total shares(sum of executed+traded shares)\n",
    "    def combine_order_aggregates(self):\n",
    "        data_frames = [self.active_agg,self.cancel_agg,self.executed_agg,self.trade_agg]\n",
    "        self.orders_agg = functools.reduce(lambda  left,right: pd.merge(left,right,on=['order_ID'],\n",
    "                                            how='outer'), data_frames).fillna(0)\n",
    "        self.orders_agg.rename(columns = {'share_symbol_y':'TradeMessage_Share_Symbol','share_symbol_x':'ActiveMessage_Share_Symbol','shares_x':'active_shares','shares_y':'traded_shares'}, inplace = True)\n",
    "        self.orders_agg['TradeMessage_Share_Symbol'] = self.orders_agg['TradeMessage_Share_Symbol'].replace([0],'NaN')\n",
    "        self.orders_agg['ActiveMessage_Share_Symbol'] = self.orders_agg['ActiveMessage_Share_Symbol'].replace([0],'NaN')\n",
    "        self.orders_agg['stock_symbol'] = np.where(self.orders_agg['ActiveMessage_Share_Symbol'] == 'NaN',self.orders_agg['TradeMessage_Share_Symbol'],self.orders_agg['ActiveMessage_Share_Symbol'])\n",
    "        self.orders_agg['order_volume'] = self.orders_agg['executed_shares'] + self.orders_agg['traded_shares']\n",
    "    \n",
    "    # orders the sum of shares for each symbol in the file in descending order\n",
    "    def process_volume_aggregate(self):\n",
    "        self.volume_agg = self.orders_agg.groupby(by =['stock_symbol']).agg({'order_volume':'sum'}).sort_values(by='order_volume', ascending=False).reset_index()\n",
    "    \n",
    "    #gets the top-10 movers for the given file.\n",
    "    def top_ten_movers(self):\n",
    "        return self.volume_agg.head(10)\n",
    "        \n",
    "        \n",
    "\n",
    "def main():\n",
    "    #Read the file with Exception Handling\n",
    "    filepath = r'pitch_example_data'\n",
    "    \n",
    "    #Can be taken as user input also\n",
    "    #filepath = raw_input(\"Enter the absolute path of the PITCH file\")\n",
    "    try:\n",
    "        raw_df = pd.read_csv(filepath, header=None,names = ['raw_message_data'])    \n",
    "    except IOError:\n",
    "        print(str(filepath) + \" is not a valid file path\" + \" or file may not be existent\")\n",
    "    \n",
    "    PitchDataObject = PitchData(raw_df)\n",
    "    PitchDataObject.extract_raw_data()\n",
    "    active_df,cancel_df,executed_df,trade_df = PitchDataObject.createMultipleDataFrames()\n",
    "    AggregateDataObject = AggregateData(active_df,cancel_df,executed_df,trade_df)\n",
    "    AggregateDataObject.process_orders()\n",
    "    AggregateDataObject.process_order_aggregates()\n",
    "    AggregateDataObject.combine_order_aggregates()\n",
    "    AggregateDataObject.process_volume_aggregate()\n",
    "    \n",
    "    output = AggregateDataObject.top_ten_movers()\n",
    "    print(output) \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing based on schema - As an extension we can plugin the schema types and slice the dataframes based on defined schema\n",
    "#  instead of wrting defined slice statements\n",
    "#Define schema dictionary for different message types\n",
    "\n",
    "# message_schemas = {\n",
    "#     'A': {'timestamp': {'offset': 0,'length': 8},\n",
    "#          'message_type': {'offset': 8,'length': 1},\n",
    "#          'order_ID': {'offset': 9,'length': 12},\n",
    "#          'side_indicator': {'offset':21,'length': 1},\n",
    "#          'shares': {'offset':22,'length':6},\n",
    "#          'stock_symbol': {'offset':28,'length':6},\n",
    "#          'price': {'offset':34,'length':10},\n",
    "#          'display': {'offset':44,'length':1}},\n",
    "    \n",
    "#     'E': {'timestamp': {'offset': 0,'length': 8},\n",
    "#          'message_type': {'offset': 8,'length': 1},\n",
    "#          'order_ID': {'offset': 9,'length': 12},\n",
    "#          'executed_shares': {'offset':21,'length': 6},\n",
    "#          'execution_id': {'offset':27,'length':12}},\n",
    "    \n",
    "#     'X':{'timestamp': {'offset': 0,'length': 8},\n",
    "#          'message_type': {'offset': 8,'length': 1},\n",
    "#          'order_ID': {'offset': 9,'length': 12},\n",
    "#          'cancelled_shares': {'offset':21,'length': 6}},\n",
    "    \n",
    "#     'P':{'timestamp': {'offset': 0,'length': 8},\n",
    "#          'message_type': {'offset': 8,'length': 1},\n",
    "#          'order_ID': {'offset': 9,'length': 12},\n",
    "#          'side_indicator': {'offset':21,'length': 1},\n",
    "#          'shares': {'offset':22,'length':6},\n",
    "#          'stock_symbol': {'offset':28,'length':6},\n",
    "#          'price': {'offset':34,'length':10},\n",
    "#          'execution_id': {'offset':44,'length':12}}}\n",
    "\n",
    "# slice the frame based on offset and length\n",
    "#     eg: cancel_df['time_stamp'] = cancel_df['raw_message_data'].str.slice(0,8,1) can be re-written as:\n",
    "#         cancel_timestamp_offset = message_schemas['A']['timestamp']['offset']\n",
    "#         cancel_timestamp_length = message_schemas['A']['timestamp']['length']\n",
    "#         cancel_df['time_stamp'] = cancel_df['raw_message_data'].str.slice(cancel_timestamp_offset,cancel_timestamp_length,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
